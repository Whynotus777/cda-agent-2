# V4 Implementation Status

**Last Updated**: 2025-11-05

## Summary

Implemented the critical simulation runner infrastructure for V4 verification-in-the-loop. This enables functional verification (pass/fail simulation) rather than proxy metrics like "All I/O Used".

## Completed ✅

### 1. Simulation Runner Implementation
- **File**: `scripts/run_iverilog_simulation.py` (350 lines)
- **Status**: ✅ Complete and ready to use
- **Features**:
  - Compiles RTL + testbench with iverilog
  - Runs simulation with vvp
  - Parses output for pass/fail
  - Detailed error reporting
  - Command-line and Python API
  - Configurable timeouts
  - JSON output support

### 2. Test Suite
- **Files**:
  - `tests/simple_counter.v` - Simple 4-bit counter RTL
  - `tests/simple_counter_tb.sv` - SystemVerilog testbench
- **Status**: ✅ Complete and ready to test
- **Purpose**: Validate simulation runner works correctly

### 3. Documentation
- **File**: `scripts/SIMULATION_RUNNER_README.md`
- **Status**: ✅ Complete
- **Contents**:
  - Installation instructions
  - Usage examples (CLI and Python API)
  - Output format specification
  - Pass/fail detection logic
  - Integration guide
  - Next steps

## Blocked ⚠️

### Installation Required

**iverilog is not installed**. The simulation runner is fully implemented but cannot be tested without iverilog.

**Required command**:
```bash
sudo apt-get install -y iverilog
```

**Verification after install**:
```bash
which iverilog  # Should show: /usr/bin/iverilog
which vvp       # Should show: /usr/bin/vvp
iverilog -v     # Should show version
```

**Alternative**: Verilator is already installed (`/usr/bin/verilator`), but requires different workflow (C++ testbenches).

## Next Steps (Pending iverilog)

### Step 2: Test Simulation Runner ⏳
```bash
python3 scripts/run_iverilog_simulation.py \
    tests/simple_counter.v \
    tests/simple_counter_tb.sv
```

Expected: Should compile, run simulation, and report PASS.

### Step 3: Re-benchmark V3 with Simulation ⏳

Update `scripts/benchmark_behavioral_model.py` to:
1. Remove "All I/O Used" metric (officially abandoned)
2. Add simulation-based functional verification
3. Report true Functional % (pass/fail from simulation)

This establishes the V3 baseline before building V4.

### Step 4: Build V4 Dataset Generator ⏳

Create `scripts/generate_v4_dataset.py`:
```python
# Verification-in-the-loop pipeline
for spec in generated_specs:
    # Generate RTL with V3 model
    rtl_code = v3_model.generate(spec)

    # Generate testbench
    testbench = generate_testbench(spec, rtl_code)

    # Run simulation
    result = run_simulation(rtl_code, testbench)

    # Keep only passing examples
    if result["passed"]:
        v4_dataset.append({
            "instruction": spec,
            "output": rtl_code,
            "metadata": {
                "functional": "verified",
                "simulation_log": result["log"]
            }
        })
```

### Step 5: Generate V4 Dataset ⏳

Target: 1000+ simulation-verified examples using verification-in-the-loop.

### Step 6: Train and Benchmark V4 ⏳

Train on V4 dataset and measure improvement in Functional %.

## Architecture

### Simulation Workflow

```
RTL (.v) + Testbench (.sv)
         ↓
    iverilog -g2012
         ↓
    sim.vvp (intermediate)
         ↓
    vvp sim.vvp
         ↓
    Parse output for pass/fail
         ↓
    Return: {"passed": bool, "log": str}
```

### Pass/Fail Detection

**Pass Indicators**:
- "Testbench completed." (from template)
- "PASS" or "PASSED" in output
- Clean $finish without errors

**Fail Indicators**:
- "FAIL" or "FAILED" in output
- Assertion failures
- Runtime errors
- Timeout

### Integration Points

1. **Benchmark script**: Add functional verification to model benchmarking
2. **Dataset generator**: Filter generated examples by simulation pass/fail
3. **Verifier**: Replace "All I/O Used" with simulation-based verification

## Technical Decisions

### Why iverilog?
- Open-source and widely used
- Simple workflow (compile → run)
- Supports SystemVerilog testbenches
- Good error messages
- Fast enough for our use case

### Why not verilator?
- Verilator is installed and available
- But requires C++ testbenches (more complex)
- iverilog is simpler for quick functional verification
- Verilator is better for performance-critical applications

### Testbench Format
- SystemVerilog (.sv)
- Generated by existing `testbench_generator.py`
- Contains stimulus and self-checks
- Uses $display for status messages
- Ends with "Testbench completed." on success

## V3 Current Status

**Training**: ✅ Complete (179 examples, 1m 52s)
**Benchmark**: ✅ Complete
**Metrics**:
- Average Score: 0.693
- Compile %: 74.0%
- **All I/O Used: 0.0%** ← Officially abandoned metric
- **Functional %: UNKNOWN** ← Needs simulation to measure

## Why This Matters

**The Paradigm Shift**: Real-world RTL (PicoRV32, SERV) has intentionally unused ports for valid reasons (future expansion, compatibility). "All I/O Used" doesn't correlate with functional correctness.

**The Only Metric That Matters**: Did the RTL pass its testbench simulation?

The simulation runner enables:
1. ✅ True functional verification (not proxy metrics)
2. ⏳ V3 baseline measurement with real functional %
3. ⏳ Verification-in-the-loop for V4 dataset
4. ⏳ Accurate model quality assessment

## Files Created

```
scripts/run_iverilog_simulation.py          # Main simulation runner (350 lines)
scripts/SIMULATION_RUNNER_README.md         # Documentation
tests/simple_counter.v                      # Test RTL
tests/simple_counter_tb.sv                  # Test testbench
V4_IMPLEMENTATION_STATUS.md                 # This file
```

## Immediate Action Required

**Install iverilog** to unblock all subsequent steps:
```bash
sudo apt-get install -y iverilog
```

Then proceed with Step 2: Test simulation runner.
